# Prompt Engineering:
Prompts can drastically changes the no of tokens used in API calls, which in turn significantly changes the cost of using the API.

- Zero-shot prompt : Prompt without any example. Using Capital words as key words or giving more specific commands to the agents. Also know as Direct prompt or Zero-shot prompt.
Good for: popular or familiar usecases

- Few-shot prompt: First provide examples then the Prompt.
Good for: org or context specific usecases

- Multi-short prompt: More no. of examples than few-shot prompoting

- Chain of Thought: Enhances performance of LLM, by asking LLM to use it's reasoning capabilites. (AI Agents)

Include -> Context, Instruction, Examples, O/p format